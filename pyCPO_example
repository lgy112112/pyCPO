{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8615798,"sourceType":"datasetVersion","datasetId":5156761},{"sourceId":8680501,"sourceType":"datasetVersion","datasetId":5203788}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/liaoguoying/pycpo-example?scriptVersionId=183267936\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport matplotlib.pyplot as plt\n\n# Read input and output data from CSV files\ninput_file_path = '/kaggle/input/capacitance-dataset/C2.csv'\noutput_file_path = '/kaggle/input/capacitance-dataset/G2.csv'\n\ninput_data = pd.read_csv(input_file_path, header=None)\noutput_data = pd.read_csv(output_file_path, header=None)\n\n# Print the shapes of the input and output data\nprint(f\"Input data shape: {input_data.shape}\")\nprint(f\"Output data shape: {output_data.shape}\")\n\n# Normalize input data to the range [0, 1]\nscaler_input = MinMaxScaler(feature_range=(0, 1))\ninput_data_scaled = scaler_input.fit_transform(input_data)\n\n# Split the dataset into training and testing sets\ninput_train, input_test, output_train, output_test = train_test_split(input_data_scaled, output_data, test_size=0.2, random_state=42)\n\n# Convert output data to numpy arrays\noutput_train = np.array(output_train)\noutput_test = np.array(output_test)\n\n# Convert data to PyTorch tensors\ninput_train_tensor = torch.tensor(input_train, dtype=torch.float32)\noutput_train_tensor = torch.tensor(output_train, dtype=torch.float32)\ninput_test_tensor = torch.tensor(input_test, dtype=torch.float32)\noutput_test_tensor = torch.tensor(output_test, dtype=torch.float32)\n\n# Create TensorDataset objects for training and testing datasets\ntrain_dataset = TensorDataset(input_train_tensor, output_train_tensor)\ntest_dataset = TensorDataset(input_test_tensor, output_test_tensor)\n\n# Create DataLoader objects to load data in batches\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Function to visualize input samples and their corresponding targets\ndef plot_samples(inputs, targets, title):\n    fig, axes = plt.subplots(2, 1, figsize=(12, 15))\n\n    # Plot the first two input samples\n    axes[0].plot(inputs[0].cpu().numpy(), label='Sample 1')\n    axes[0].plot(inputs[1].cpu().numpy(), label='Sample 2')\n    axes[0].set_title(f'{title} - Input Samples')\n    axes[0].legend()\n\n    # Plot the corresponding targets for the first two input samples\n    axes[1].plot(targets[0].cpu().numpy(), label='Target 1')\n    axes[1].plot(targets[1].cpu().numpy(), label='Target 2')\n    axes[1].set_title(f'{title} - Output Targets (DFT)')\n    axes[1].legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Check the DataLoader and display a sample batch\nfor batch_idx, (inputs, targets) in enumerate(train_loader):\n    print(f\"Batch {batch_idx+1} (Training)\")\n    print(f\"Inputs: {inputs.size()}\")\n    print(f\"Targets: {targets.size()}\")\n    plot_samples(inputs, targets, \"Training\")\n    if batch_idx == 0:\n        break  # Only display the first batch\n\nfor batch_idx, (inputs, targets) in enumerate(test_loader):\n    print(f\"Batch {batch_idx+1} (Testing)\")\n    print(f\"Inputs: {inputs.size()}\")\n    print(f\"Targets: {targets.size()}\")\n    plot_samples(inputs, targets, \"Testing\")\n    if batch_idx == 0:\n        break  # Only display the first batch\n\n# Ensure data dimensions are as expected\nprint(f\"Expected input size: {[batch_size, input_train.shape[1]]}\")\nprint(f\"Example training input size: {next(iter(train_loader))[0].size()}\")\nprint(f\"Example testing input size: {next(iter(test_loader))[0].size()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:49:27.955391Z","iopub.execute_input":"2024-06-13T07:49:27.955948Z","iopub.status.idle":"2024-06-13T07:49:35.306949Z","shell.execute_reply.started":"2024-06-13T07:49:27.95591Z","shell.execute_reply":"2024-06-13T07:49:35.305331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# one way CNN-LSTM-Attention","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Determine the device to use (GPU if available, otherwise CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass Attention(nn.Module):\n    def __init__(self, lstm_units):\n        super(Attention, self).__init__()\n        # Define the attention mechanism as a sequential model\n        self.attention = nn.Sequential(\n            nn.Linear(lstm_units, 128),  # Linear layer to project LSTM output\n            nn.ReLU(True),  # ReLU activation\n            nn.Linear(128, 1)  # Linear layer to produce attention weights\n        )\n\n    def forward(self, lstm_output):\n        # Compute attention weights\n        attention_weights = self.attention(lstm_output)\n        attention_weights = torch.softmax(attention_weights, dim=1)  # Apply softmax to get probabilities\n        # Compute the context vector as a weighted sum of LSTM outputs\n        context_vector = torch.sum(attention_weights * lstm_output, dim=1)\n        return context_vector, attention_weights\n\nclass CNN1DModelWithLSTMAndAttention(nn.Module):\n    def __init__(self, input_size, num_classes, lstm_units, conv_filters, fc_units):\n        super(CNN1DModelWithLSTMAndAttention, self).__init__()\n        \n        # Define 1D convolutional layers\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=conv_filters[0], kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels=conv_filters[0], out_channels=conv_filters[1], kernel_size=3, padding=1)\n        self.conv3 = nn.Conv1d(in_channels=conv_filters[1], out_channels=conv_filters[2], kernel_size=3, padding=1)\n        self.conv4 = nn.Conv1d(in_channels=conv_filters[2], out_channels=conv_filters[3], kernel_size=3, padding=1)\n        self.conv5 = nn.Conv1d(in_channels=conv_filters[3], out_channels=conv_filters[4], kernel_size=3, padding=1)\n        \n        # Define batch normalization layers\n        self.bn1 = nn.BatchNorm1d(conv_filters[0])\n        self.bn2 = nn.BatchNorm1d(conv_filters[1])\n        self.bn3 = nn.BatchNorm1d(conv_filters[2])\n        self.bn4 = nn.BatchNorm1d(conv_filters[3])\n        self.bn5 = nn.BatchNorm1d(conv_filters[4])\n        \n        # Define activation function\n        self.relu = nn.ReLU()\n        \n        # Define max pooling layer\n        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n        \n        # Calculate the output size after convolution and pooling layers\n        conv_output_size = input_size // (2**5)  # Size reduced by a factor of 2 for each of the 5 pooling layers\n        \n        # Define LSTM layer\n        self.lstm = nn.LSTM(input_size=(conv_filters[4] * conv_output_size), hidden_size=lstm_units, batch_first=True)\n        \n        # Define attention mechanism\n        self.attention = Attention(lstm_units)\n        \n        # Define fully connected layers\n        self.fc1 = nn.Linear(lstm_units, fc_units[0])\n        self.fc2 = nn.Linear(fc_units[0], fc_units[1])\n        self.fc3 = nn.Linear(fc_units[1], num_classes)\n        \n        # Define dropout layer\n        self.dropout = nn.Dropout(p=0.5)\n        \n    def forward(self, x):\n        # Apply convolutional layers with ReLU activation and max pooling\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x)\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        x = self.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x)\n        x = self.relu(self.bn4(self.conv4(x)))\n        x = self.pool(x)\n        x = self.relu(self.bn5(self.conv5(x)))\n        x = self.pool(x)\n        \n        # Flatten the output for LSTM input\n        x = x.view(x.size(0), -1)\n\n        # Pass through LSTM layer\n        x, _ = self.lstm(x.unsqueeze(1))  # Add time step dimension\n\n        # Apply attention mechanism\n        context_vector, attention_weights = self.attention(x)\n        \n        # Pass through fully connected layers with ReLU activation and dropout\n        x = self.relu(self.fc1(context_vector))\n        x = self.dropout(x)\n        x = self.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n# Define model parameters\ninput_size = 66  # Number of input features\nnum_classes = 3228  # Number of output features\n\nlstm_units = 32  # Number of LSTM units\nconv_filters = [8, 16, 32, 64, 128]  # Number of filters in convolutional layers\nfc_units = [512, 256]  # Number of units in fully connected layers\n\n# Create model instance\nmodel = CNN1DModelWithLSTMAndAttention(input_size, num_classes, lstm_units, conv_filters, fc_units).to(device)\n\n# Create a sample input tensor for testing\nbatch_size = 32\nexample_input = torch.randn(batch_size, 1, input_size).to(device)\n\n# Perform a forward pass\noutput = model(example_input)\n\n# Print input and output shapes\nprint(f\"Input tensor shape: {example_input.shape}\")\nprint(f\"Output tensor shape: {output.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:52:49.314363Z","iopub.execute_input":"2024-06-13T07:52:49.314794Z","iopub.status.idle":"2024-06-13T07:52:49.557303Z","shell.execute_reply.started":"2024-06-13T07:52:49.314762Z","shell.execute_reply":"2024-06-13T07:52:49.556032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n\n# Display model summary using torchinfo\nsummary(model, input_size=(batch_size, 1, input_size))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:54:46.487693Z","iopub.execute_input":"2024-06-13T07:54:46.488163Z","iopub.status.idle":"2024-06-13T07:54:46.522928Z","shell.execute_reply.started":"2024-06-13T07:54:46.488121Z","shell.execute_reply":"2024-06-13T07:54:46.521715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom IPython.display import clear_output\n\n# Define the device to use (GPU if available, otherwise CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef initialization(SearchAgents_no, dim, ub, lb):\n    \"\"\"\n    Initialize the positions of search agents within the given bounds.\n    \n    Parameters:\n    SearchAgents_no (int): Number of search agents.\n    dim (int): Dimension of the search space.\n    ub (list or array): Upper bounds of the search space.\n    lb (list or array): Lower bounds of the search space.\n    \n    Returns:\n    Positions (array): Initialized positions of search agents.\n    \"\"\"\n    Boundary_no = len(ub)\n    Positions = np.zeros((SearchAgents_no, dim))\n    \n    if Boundary_no == 1:\n        # If all dimensions have the same bounds\n        Positions = np.random.rand(SearchAgents_no, dim) * (ub - lb) + lb\n    else:\n        # If each dimension has different bounds\n        for i in range(dim):\n            ub_i = ub[i]\n            lb_i = lb[i]\n            Positions[:, i] = np.random.rand(SearchAgents_no) * (ub_i - lb_i) + lb_i\n    return Positions\n\ndef CPO(Pop_size, Tmax, lb, ub, dim, fobj):\n    \"\"\"\n    Execute the Crested Porcupine Optimizer algorithm.\n    \n    Parameters:\n    Pop_size (int): Population size (number of search agents).\n    Tmax (int): Maximum number of iterations.\n    lb (list or array): Lower bounds of the search space.\n    ub (list or array): Upper bounds of the search space.\n    dim (int): Dimension of the search space.\n    fobj (function): Objective function to be minimized.\n    \n    Returns:\n    Gb_Fit (float): Best fitness value found.\n    Gb_Sol (array): Best solution found.\n    Conv_curve (array): Convergence curve of the best fitness value over iterations.\n    \"\"\"\n    Conv_curve = np.zeros(Tmax)  # Array to store the best fitness value at each iteration\n    ub = np.array(ub)\n    lb = np.array(lb)\n    \n    X = initialization(Pop_size, dim, ub, lb)  # Initialize the positions of search agents\n    t = 0  # Iteration counter\n    \n    # Evaluate the fitness of initial positions\n    fitness = np.array([fobj(X[i, :]) for i in range(Pop_size)])\n    Gb_Fit = np.min(fitness)  # Best fitness value\n    Gb_Sol = X[np.argmin(fitness), :]  # Best solution\n    \n    Xp = X.copy()  # Copy of the current positions\n    \n    # Optimization loop\n    with tqdm(total=Tmax, desc='CPO Optimization', unit='iter') as pbar:\n        while t < Tmax:\n            for i in range(Pop_size):\n                U1 = np.random.rand(dim) > np.random.rand()\n                if np.random.rand() < np.random.rand():\n                    if np.random.rand() < np.random.rand():\n                        y = (X[i, :] + X[np.random.randint(Pop_size), :]) / 2\n                        X[i, :] = X[i, :] + (np.random.randn() * abs(2 * np.random.rand() * Gb_Sol - y))\n                    else:\n                        y = (X[i, :] + X[np.random.randint(Pop_size), :]) / 2\n                        X[i, :] = (U1 * X[i, :]) + ((1 - U1) * (y + np.random.rand() * (X[np.random.randint(Pop_size), :] - X[np.random.randint(Pop_size), :])))\n                else:\n                    Yt = 2 * np.random.rand() * (1 - t / Tmax) ** (t / Tmax)\n                    U2 = (np.random.rand(dim) < 0.5) * 2 - 1\n                    S = np.random.rand() * U2\n                    if np.random.rand() < 0.8:\n                        St = np.exp(fitness[i] / (np.sum(fitness) + np.finfo(float).eps))\n                        S = S * Yt * St\n                        X[i, :] = (1 - U1) * X[i, :] + U1 * (X[np.random.randint(Pop_size), :] + St * (X[np.random.randint(Pop_size), :] - X[np.random.randint(Pop_size), :]) - S)\n                    else:\n                        Mt = np.exp(fitness[i] / (np.sum(fitness) + np.finfo(float).eps))\n                        vt = X[i, :]\n                        Vtp = X[np.random.randint(Pop_size), :]\n                        Ft = np.random.rand(dim) * (Mt * (-vt + Vtp))\n                        S = S * Yt * Ft\n                        X[i, :] = Gb_Sol + 0.2 * (1 - np.random.rand()) + np.random.rand() * (U2 * Gb_Sol - X[i, :]) - S\n                \n                # Ensure the positions are within the bounds\n                X[i, :] = np.clip(X[i, :], lb, ub)\n                nF = fobj(X[i, :])  # Evaluate the fitness of the new position\n                if fitness[i] < nF:\n                    X[i, :] = Xp[i, :]\n                else:\n                    Xp[i, :] = X[i, :]\n                    fitness[i] = nF\n                    if fitness[i] <= Gb_Fit:\n                        Gb_Sol = X[i, :]\n                        Gb_Fit = fitness[i]\n                        \n            t += 1\n            Conv_curve[t - 1] = Gb_Fit  # Update the convergence curve\n            pbar.set_postfix({'Best Fitness': Gb_Fit, 'Iteration': t})\n            pbar.update(1)\n        pbar.close()\n    \n    return Gb_Fit, Gb_Sol, Conv_curve\n\ndef fobj(params):\n    \"\"\"\n    Objective function for hyperparameter optimization of a neural network.\n    \n    Parameters:\n    params (array): Array of hyperparameters to be optimized.\n    \n    Returns:\n    test_loss (float): Average test loss of the neural network with the given hyperparameters.\n    \"\"\"\n    # Extract hyperparameters from the params array\n    lstm_units = int(params[0])\n    conv_filters_1 = int(params[1])\n    conv_filters_2 = int(params[2])\n    conv_filters_3 = int(params[3])\n    conv_filters_4 = int(params[4])\n    conv_filters_5 = int(params[5])\n    fc_units_1 = int(params[6])\n    fc_units_2 = int(params[7])\n    learning_rate = params[8]\n    \n    conv_filters = [conv_filters_1, conv_filters_2, conv_filters_3, conv_filters_4, conv_filters_5]\n    fc_units = [fc_units_1, fc_units_2]\n    \n    # Define the model with the given hyperparameters\n    model = CNN1DModelWithLSTMAndAttention(input_size, num_classes, lstm_units, conv_filters, fc_units).to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    \n    num_epochs = 10\n    for epoch in range(num_epochs):\n        model.train()\n        train_bar = tqdm(train_loader, desc=f'Optimization Epoch {epoch+1}/{num_epochs} (Training)', unit='batch')\n        for X_batch, y_batch in train_bar:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n            train_bar.set_postfix({'Loss': loss.item()})\n        train_bar.close()\n    \n    model.eval()\n    test_loss = 0\n    with torch.no_grad():\n        test_bar = tqdm(test_loader, desc='Validation (Testing)', unit='batch')\n        for X_batch, y_batch in test_bar:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            test_loss += loss.item()\n            test_bar.set_postfix({'Loss': loss.item()})\n        test_bar.close()\n    \n    return test_loss / len(test_loader)\n\n# CPO algorithm parameters\nPop_size = 10\nTmax = 10\ndim = 9  # Number of hyperparameters to optimize\nlb = [10, 16, 16, 16, 16, 16, 50, 50, 0.00001]  # Lower bounds of hyperparameters\nub = [512, 128, 128, 128, 128, 128, 2048, 1024, 0.001]  # Upper bounds of hyperparameters\n\n# Use CPO to optimize hyperparameters\nBest_fit, Best_sol, Conv_curve = CPO(Pop_size, Tmax, lb, ub, dim, fobj)\nclear_output(wait=True)\nprint(f\"Best parameters found: {Best_sol}\")\n\n# Plot the convergence curve\nplt.figure()\nplt.plot(Conv_curve)\nplt.title('Convergence Curve')\nplt.xlabel('Iteration')\nplt.ylabel('Best Fitness')\nplt.grid()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:57:10.406345Z","iopub.execute_input":"2024-06-13T07:57:10.406771Z","iopub.status.idle":"2024-06-13T07:57:15.152061Z","shell.execute_reply.started":"2024-06-13T07:57:10.406738Z","shell.execute_reply":"2024-06-13T07:57:15.150161Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train it with non-opted network (Control)","metadata":{}},{"cell_type":"code","source":"import os\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\nimport datetime\nimport pandas as pd\n\n# Determine the device to use (GPU if available, otherwise CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize the model with initial parameters\nmodel = CNN1DModelWithLSTMAndAttention(input_size, num_classes, lstm_units, conv_filters, fc_units).to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\n\n# Define R2 score function\ndef r2_score(y_true, y_pred):\n    y_true_mean = torch.mean(y_true)\n    ss_tot = torch.sum((y_true - y_true_mean) ** 2)\n    ss_res = torch.sum((y_true - y_pred) ** 2)\n    r2 = 1 - (ss_res / ss_tot)\n    return r2.item()\n\n# Record losses and R2 scores during training and testing\ntrain_losses = []\ntrain_r2_scores = []\ntest_losses = []\ntest_r2_scores = []\n\n# Get current time and create a folder for saving results\ncurrent_time = datetime.datetime.now().strftime(\"%m%d%H%M\")\nfolder_name = f\"origin_model_{current_time}\"\nos.makedirs(folder_name, exist_ok=True)\n\n# Train the model\nnum_epochs = 200  # Number of epochs for training\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    train_r2 = 0\n    train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n    for X_batch, y_batch in train_bar:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        train_r2 += r2_score(y_batch, outputs)\n        train_bar.set_postfix(loss=train_loss/len(train_bar), r2=train_r2/len(train_bar))\n    \n    train_losses.append(train_loss / len(train_loader))\n    train_r2_scores.append(train_r2 / len(train_loader))\n    \n    model.eval()\n    test_loss = 0\n    test_r2 = 0\n    with torch.no_grad():\n        test_bar = tqdm(test_loader, desc='Validation', unit='batch')\n        for X_batch, y_batch in test_bar:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n\n            outputs = model(X_batch)\n\n            loss = criterion(outputs, y_batch)\n            test_loss += loss.item()\n            test_r2 += r2_score(y_batch, outputs)\n            test_bar.set_postfix(loss=test_loss/len(test_bar), r2=test_r2/len(test_bar))\n    \n    test_losses.append(test_loss / len(test_loader))\n    test_r2_scores.append(test_r2 / len(test_loader))\n    \n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Train R2: {train_r2/len(train_loader):.4f}, Test Loss: {test_loss/len(test_loader):.4f}, Test R2: {test_r2/len(test_loader):.4f}')\n\n# Save the training and validation loss and R2 score to CSV file\nhistory_df = pd.DataFrame({\n    'Epoch': range(1, num_epochs + 1),\n    'Train Loss': train_losses,\n    'Train R2': train_r2_scores,\n    'Test Loss': test_losses,\n    'Test R2': test_r2_scores\n})\nhistory_df.to_csv(os.path.join(folder_name, 'training_history.csv'), index=False)\n\n# Plot and save the loss and R2 score curves\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\nplt.plot(range(1, num_epochs+1), test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs+1), train_r2_scores, label='Train R2')\nplt.plot(range(1, num_epochs+1), test_r2_scores, label='Test R2')\nplt.xlabel('Epoch')\nplt.ylabel('R2 Score')\nplt.title('R2 Score over Epochs')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig(os.path.join(folder_name, 'loss_r2_curve.png'))  # Save to file\nplt.show()\n\n# Predict and visualize results on the test set\nmodel.eval()\nwith torch.no_grad():\n    for batch_idx, (inputs, targets) in enumerate(test_loader):\n        if batch_idx == 0:\n            inputs, targets = inputs.to(device), targets.to(device)\n            inputs = inputs.unsqueeze(1)  # Add channel dimension\n            outputs = model(inputs)\n            \n            # Move inputs, predictions, and targets to CPU for visualization\n            inputs = inputs.cpu().numpy()\n            outputs = outputs.cpu().numpy()\n            targets = targets.cpu().numpy()\n            \n            # Visualize actual and predicted results\n            fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n            # Randomly select a sample for visualization\n            sample_idx = random.randint(0, inputs.shape[0] - 1)\n            axes[0].plot(targets[sample_idx], label='Actual')\n            axes[0].set_title('Actual Output')\n            axes[0].legend()\n\n            axes[1].plot(outputs[sample_idx], label='Predicted')\n            axes[1].set_title('Predicted Output')\n            axes[1].legend()\n\n            # Overlay of actual and predicted outputs\n            axes[2].plot(targets[sample_idx], label='Actual', alpha=0.7)\n            axes[2].plot(outputs[sample_idx], label='Predicted', alpha=0.7)\n            axes[2].set_title('Overlay of Actual and Predicted Output')\n            axes[2].legend()\n\n            plt.savefig(os.path.join(folder_name, 'actual_vs_predicted.png'))  # Save to file\n            plt.show()\n            break\n\n# Compute final R2 score on the test set\nmodel.eval()\nfinal_test_r2 = 0\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n        outputs = model(X_batch)\n        final_test_r2 += r2_score(y_batch, outputs)\n\nfinal_test_r2 /= len(test_loader)\nprint(f\"Final Test R2: {final_test_r2:.4f}\")\n\n# Save the model\nmodel_name = f\"{model.__class__.__name__}_R2_{final_test_r2:.4f}_{current_time}_VANILLA.pt\"\ntorch.save(model.state_dict(), os.path.join(folder_name, model_name))\nprint(f\"Model saved as {os.path.join(folder_name, model_name)}\")\n\n# Predict on the test set and save results\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n        outputs = model(X_batch)\n        predictions.append(outputs.cpu().numpy())\n\n# Convert predictions to numpy array\npredictions = np.vstack(predictions)\n\n# Save predictions to CSV file\npredictions_df = pd.DataFrame(predictions)\npredictions_df.to_csv(os.path.join(folder_name, 'predictions.csv'), index=False)\n\nprint(f\"Predictions saved to {os.path.join(folder_name, 'predictions.csv')}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:58:52.456517Z","iopub.execute_input":"2024-06-13T07:58:52.456907Z","iopub.status.idle":"2024-06-13T07:58:56.456487Z","shell.execute_reply.started":"2024-06-13T07:58:52.456876Z","shell.execute_reply":"2024-06-13T07:58:56.454638Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train it with the Best Params","metadata":{}},{"cell_type":"code","source":"import os\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\nimport datetime\nimport pandas as pd\n\n# Determine the device to use (GPU if available, otherwise CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Read the best parameters from CSV file\nbest_params_path = '/kaggle/input/best-params/best_parameters.csv' # your path to the params.csv\n# if you don't want to extract the best params, just source it from input space: /kaggle/input/best-params/best_parameters.csv\nbest_params_df = pd.read_csv(best_params_path)\nbest_params = best_params_df.iloc[0].values\n\n# Extract the best parameters\nlstm_units = int(best_params[0])\nconv_filters = [int(best_params[1]), int(best_params[2]), int(best_params[3]), int(best_params[4]), int(best_params[5])]\nfc_units = [int(best_params[6]), int(best_params[7])]\n\n# Initialize the model with the best parameters\nmodel = CNN1DModelWithLSTMAndAttention(input_size, num_classes, lstm_units, conv_filters, fc_units).to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\n\n# Define R2 score function\ndef r2_score(y_true, y_pred):\n    y_true_mean = torch.mean(y_true)\n    ss_tot = torch.sum((y_true - y_true_mean) ** 2)\n    ss_res = torch.sum((y_true - y_pred) ** 2)\n    r2 = 1 - (ss_res / ss_tot)\n    return r2.item()\n\n# Record losses and R2 scores during training and testing\ntrain_losses = []\ntrain_r2_scores = []\ntest_losses = []\ntest_r2_scores = []\n\n# Get current time and create a folder for saving results\ncurrent_time = datetime.datetime.now().strftime(\"%m%d%H%M\")\nfolder_name = f\"CPO_model_{current_time}\"\nos.makedirs(folder_name, exist_ok=True)\n\n# Train the model\nnum_epochs = 200  # Number of epochs for training\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    train_r2 = 0\n    train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n    for X_batch, y_batch in train_bar:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        train_r2 += r2_score(y_batch, outputs)\n        train_bar.set_postfix(loss=train_loss/len(train_bar), r2=train_r2/len(train_bar))\n    \n    train_losses.append(train_loss / len(train_loader))\n    train_r2_scores.append(train_r2 / len(train_loader))\n    \n    model.eval()\n    test_loss = 0\n    test_r2 = 0\n    with torch.no_grad():\n        test_bar = tqdm(test_loader, desc='Validation', unit='batch')\n        for X_batch, y_batch in test_bar:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n\n            outputs = model(X_batch)\n\n            loss = criterion(outputs, y_batch)\n            test_loss += loss.item()\n            test_r2 += r2_score(y_batch, outputs)\n            test_bar.set_postfix(loss=test_loss/len(test_bar), r2=test_r2/len(test_bar))\n    \n    test_losses.append(test_loss / len(test_loader))\n    test_r2_scores.append(test_r2 / len(test_loader))\n    \n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Train R2: {train_r2/len(train_loader):.4f}, Test Loss: {test_loss/len(test_loader):.4f}, Test R2: {test_r2/len(test_loader):.4f}')\n\n# Save the training and validation loss and R2 score to CSV file\nhistory_df = pd.DataFrame({\n    'Epoch': range(1, num_epochs + 1),\n    'Train Loss': train_losses,\n    'Train R2': train_r2_scores,\n    'Test Loss': test_losses,\n    'Test R2': test_r2_scores\n})\nhistory_df.to_csv(os.path.join(folder_name, 'training_history_CPO.csv'), index=False)\n\n# Plot and save the loss and R2 score curves\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\nplt.plot(range(1, num_epochs+1), test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs+1), train_r2_scores, label='Train R2')\nplt.plot(range(1, num_epochs+1), test_r2_scores, label='Test R2')\nplt.xlabel('Epoch')\nplt.ylabel('R2 Score')\nplt.title('R2 Score over Epochs')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig(os.path.join(folder_name, 'loss_r2_curve_CPO.png'))  # Save to file\nplt.show()\n\n# Predict and visualize results on the test set\nmodel.eval()\nwith torch.no_grad():\n    for batch_idx, (inputs, targets) in enumerate(test_loader):\n        if batch_idx == 0:\n            inputs, targets = inputs.to(device), targets.to(device)\n            inputs = inputs.unsqueeze(1)  # Add channel dimension\n            outputs = model(inputs)\n            \n            # Move inputs, predictions, and targets to CPU for visualization\n            inputs = inputs.cpu().numpy()\n            outputs = outputs.cpu().numpy()\n            targets = targets.cpu().numpy()\n            \n            # Visualize actual and predicted results\n            fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n            # Randomly select a sample for visualization\n            sample_idx = random.randint(0, inputs.shape[0] - 1)\n            axes[0].plot(targets[sample_idx], label='Actual')\n            axes[0].set_title('Actual Output')\n            axes[0].legend()\n\n            axes[1].plot(outputs[sample_idx], label='Predicted')\n            axes[1].set_title('Predicted Output')\n            axes[1].legend()\n\n            # Overlay of actual and predicted outputs\n            axes[2].plot(targets[sample_idx], label='Actual', alpha=0.7)\n            axes[2].plot(outputs[sample_idx], label='Predicted', alpha=0.7)\n            axes[2].set_title('Overlay of Actual and Predicted Output')\n            axes[2].legend()\n\n            plt.savefig(os.path.join(folder_name, 'actual_vs_predicted_CPO.png'))  # Save to file\n            plt.show()\n            break\n\n# Compute final R2 score on the test set\nmodel.eval()\nfinal_test_r2 = 0\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n        outputs = model(X_batch)\n        final_test_r2 += r2_score(y_batch, outputs)\n\nfinal_test_r2 /= len(test_loader)\nprint(f\"Final Test R2: {final_test_r2:.4f}\")\n\n# Save the model\nmodel_name = f\"{model.__class__.__name__}_R2_{final_test_r2:.4f}_{current_time}_CPO.pt\"\ntorch.save(model.state_dict(), os.path.join(folder_name, model_name))\nprint(f\"Model saved as {os.path.join(folder_name, model_name)}\")\n\n# Predict on the test set and save results\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        X_batch = X_batch.unsqueeze(1)  # Add channel dimension\n        outputs = model(X_batch)\n        predictions.append(outputs.cpu().numpy())\n\n# Convert predictions to numpy array\npredictions = np.vstack(predictions)\n\n# Save predictions to CSV file\npredictions_df = pd.DataFrame(predictions)\npredictions_df.to_csv(os.path.join(folder_name, 'predictions_CPO.csv'), index=False)\n\nprint(f\"Predictions saved to {os.path.join(folder_name, 'predictions_CPO.csv')}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:06:04.971574Z","iopub.execute_input":"2024-06-13T08:06:04.972058Z","iopub.status.idle":"2024-06-13T08:06:10.045889Z","shell.execute_reply.started":"2024-06-13T08:06:04.972024Z","shell.execute_reply":"2024-06-13T08:06:10.044196Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# To Compare","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV files containing training history\norigin_history_path = '/teamspace/studios/this_studio/origin_model_06080733/training_history.csv'\ncpo_history_path = '/teamspace/studios/this_studio/CPO_model_06080724/training_history_CPO.csv'\n\norigin_history = pd.read_csv(origin_history_path)\ncpo_history = pd.read_csv(cpo_history_path)\n\n# Extract epochs for comparison\nepochs = origin_history['Epoch']\n\n# Create a figure for plotting the comparison graphs\nplt.figure(figsize=(14, 12))\n\n# Plot Train Loss comparison\nplt.subplot(2, 2, 1)\nplt.plot(epochs, origin_history['Train Loss'], label='Origin Model Train Loss')\nplt.plot(epochs, cpo_history['Train Loss'], label='CPO Model Train Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Train Loss')\nplt.title('Train Loss Comparison')\nplt.legend()\n\n# Plot Test Loss comparison\nplt.subplot(2, 2, 2)\nplt.plot(epochs, origin_history['Test Loss'], label='Origin Model Test Loss')\nplt.plot(epochs, cpo_history['Test Loss'], label='CPO Model Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Test Loss')\nplt.title('Test Loss Comparison')\nplt.legend()\n\n# Plot Train R2 comparison\nplt.subplot(2, 2, 3)\nplt.plot(epochs, origin_history['Train R2'], label='Origin Model Train R2')\nplt.plot(epochs, cpo_history['Train R2'], label='CPO Model Train R2')\nplt.xlabel('Epoch')\nplt.ylabel('Train R2')\nplt.title('Train R2 Comparison')\nplt.legend()\n\n# Plot Test R2 comparison\nplt.subplot(2, 2, 4)\nplt.plot(epochs, origin_history['Test R2'], label='Origin Model Test R2')\nplt.plot(epochs, cpo_history['Test R2'], label='CPO Model Test R2')\nplt.xlabel('Epoch')\nplt.ylabel('Test R2')\nplt.title('Test R2 Comparison')\nplt.legend()\n\n# Adjust layout to prevent overlapping\nplt.tight_layout()\nplt.show()\n\n# Print final results for both models for comparison\nprint(\"Final Results Comparison:\")\nprint(f\"Origin Model Final Train Loss: {origin_history['Train Loss'].iloc[-1]:.4f}\")\nprint(f\"CPO Model Final Train Loss: {cpo_history['Train Loss'].iloc[-1]:.4f}\")\nprint(f\"Origin Model Final Test Loss: {origin_history['Test Loss'].iloc[-1]:.4f}\")\nprint(f\"CPO Model Final Test Loss: {cpo_history['Test Loss'].iloc[-1]:.4f}\")\nprint(f\"Origin Model Final Train R2: {origin_history['Train R2'].iloc[-1]:.4f}\")\nprint(f\"CPO Model Final Train R2: {cpo_history['Train R2'].iloc[-1]:.4f}\")\nprint(f\"Origin Model Final Test R2: {origin_history['Test R2'].iloc[-1]:.4f}\")\nprint(f\"CPO Model Final Test R2: {cpo_history['Test R2'].iloc[-1]:.4f}\")\n","metadata":{},"execution_count":null,"outputs":[]}]}